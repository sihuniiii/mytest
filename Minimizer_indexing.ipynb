{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXx4ccFNFXubzXbmWR9CMx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sihuniiii/mytest/blob/main/Minimizer_indexing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BayC7vh_RXdo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def generate_reference_to_file(filename, length, chunk_size=10_000_000):\n",
        "    bases = ['A', 'C', 'G', 'T']\n",
        "    with open(filename, 'w') as f:\n",
        "        written = 0\n",
        "        while written < length:\n",
        "            to_write = min(chunk_size, length - written)\n",
        "            seq_chunk = ''.join(random.choices(bases, k=to_write))\n",
        "            f.write(seq_chunk)\n",
        "            written += to_write\n",
        "\n",
        "def simulate_ancient_reads_to_file(\n",
        "    reference_file,\n",
        "    reads_filename,\n",
        "    truth_filename,\n",
        "    read_len,\n",
        "    num_reads,\n",
        "    mutation_rate=0.02\n",
        "):\n",
        "    with open(reference_file, 'r') as f:\n",
        "        reference_seq = f.read().strip()\n",
        "    L = len(reference_seq)\n",
        "\n",
        "    with open(reads_filename, 'w') as rf, open(truth_filename, 'w') as tf:\n",
        "        for i in range(num_reads):\n",
        "            start = random.randint(0, L - read_len)\n",
        "            original = list(reference_seq[start : start + read_len])\n",
        "            mutated = []\n",
        "            for j, base in enumerate(original):\n",
        "                prob = mutation_rate\n",
        "                if j < 5 or j >= read_len - 5:\n",
        "                    prob *= 5\n",
        "                if random.random() < prob:\n",
        "                    if base == 'C':\n",
        "                        mutated.append('T')\n",
        "                    elif base == 'G':\n",
        "                        mutated.append('A')\n",
        "                    else:\n",
        "                        mutated.append(random.choice(['A', 'C', 'G', 'T']))\n",
        "                else:\n",
        "                    mutated.append(base)\n",
        "            read_str = ''.join(mutated)\n",
        "            rf.write(read_str + '\\n')\n",
        "            tf.write(f\"{start}\\n\")\n",
        "\n",
        "def run_simulation():\n",
        "    settings = [\n",
        "        (1_000_000,100_000,\"1M\", \"100K\"),\n",
        "        (10_000_000,1_000_000,\"10M\", \"1M\"),\n",
        "        (100_000_000,10_000_000,\"100M\",\"10M\"),\n",
        "        (1_000_000_000,100_000_000,\"1T\", \"100M\"),\n",
        "    ]\n",
        "\n",
        "    # Reference 생성\n",
        "    for ref_len, _, ref_tag, _ in settings:\n",
        "        ref_filename = f\"reference_{ref_tag}.txt\"\n",
        "        if not os.path.exists(ref_filename):\n",
        "            generate_reference_to_file(ref_filename, ref_len)\n",
        "\n",
        "    for ref_len, num_reads, ref_tag, read_tag in settings:\n",
        "        ref_filename   = f\"reference_{ref_tag}.txt\"\n",
        "        reads_filename = f\"mammoth_reads_{read_tag}.txt\"\n",
        "        truth_filename = f\"ground_truth_{read_tag}.txt\"\n",
        "        read_len = 100\n",
        "\n",
        "        if not (os.path.exists(reads_filename) and os.path.exists(truth_filename)):\n",
        "            simulate_ancient_reads_to_file(\n",
        "                reference_file=ref_filename,\n",
        "                reads_filename=reads_filename,\n",
        "                truth_filename=truth_filename,\n",
        "                read_len=read_len,\n",
        "                num_reads=num_reads,\n",
        "                mutation_rate=0.01\n",
        "            )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_simulation()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#파일 불러오기\n",
        "def load_reference_to_string(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        return f.read().strip()\n",
        "\n",
        "def load_reads_from_file(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        return [line.strip() for line in f]\n",
        "\n",
        "def load_truth_positions(filename):\n",
        "    return [int(line.strip()) for line in open(filename, 'r')]\n",
        "\n",
        "\n",
        "# Minimizer 인덱스\n",
        "def build_minimizer_index(reference, k=20, w=8, max_occ=500):\n",
        "    index = {}\n",
        "    num_kmers = len(reference) - k + 1\n",
        "    for i in range(num_kmers - w + 1):\n",
        "        window_kmers = [reference[j:j + k] for j in range(i, i + w)]\n",
        "        mn = min(window_kmers)\n",
        "        mn_pos = i + window_kmers.index(mn)\n",
        "        index.setdefault(mn, []).append(mn_pos)\n",
        "\n",
        "    filtered = {m: poses for m, poses in index.items() if len(poses) <= max_occ}\n",
        "    return filtered\n",
        "\n",
        "# 매칭 알고리즘\n",
        "def minimizer_match(\n",
        "    reference,index,read,\n",
        "    k=20,w=8,\n",
        "    max_mismatch=2,seed_min=2\n",
        "):\n",
        "    read_kmers = [read[i:i + k] for i in range(len(read) - k + 1)]\n",
        "    read_min_pairs = []\n",
        "    for i in range(len(read_kmers) - w + 1):\n",
        "        window = read_kmers[i:i + w]\n",
        "        mn = min(window)\n",
        "        mn_idx = window.index(mn)\n",
        "        read_pos = i + mn_idx\n",
        "        read_min_pairs.append((mn, read_pos))\n",
        "\n",
        "    delta_counts = {}\n",
        "    for mn, rpos in read_min_pairs:\n",
        "        if mn not in index:\n",
        "            continue\n",
        "        for refpos in index[mn]:\n",
        "            delta = refpos - rpos\n",
        "            delta_counts[delta] = delta_counts.get(delta, 0) + 1\n",
        "\n",
        "    candidates = [d for d, cnt in delta_counts.items() if cnt >= seed_min]\n",
        "    best_pos, best_mm = -1, max_mismatch + 1\n",
        "\n",
        "    for delta in candidates:\n",
        "        if delta < 0 or delta + len(read) > len(reference):\n",
        "            continue\n",
        "        window_seq = reference[delta : delta + len(read)]\n",
        "        mismatches = sum(1 for a, b in zip(read, window_seq) if a != b)\n",
        "        if mismatches <= max_mismatch and mismatches < best_mm:\n",
        "            best_mm = mismatches\n",
        "            best_pos = delta\n",
        "\n",
        "    return best_pos, best_mm\n",
        "\n",
        "# 복원 함수\n",
        "def reconstruct_genome_with_reads(\n",
        "    reference,\n",
        "    reads,\n",
        "    truth_positions,\n",
        "    index,\n",
        "    k=20, w=8, max_mismatch=2, seed_min=2\n",
        "):\n",
        "    reconstructed = list(reference)\n",
        "    matched_reads = 0\n",
        "    total_reads = len(reads)\n",
        "\n",
        "    for i, read in enumerate(reads):\n",
        "        true_pos = truth_positions[i]\n",
        "        pred_pos, mm = minimizer_match(\n",
        "            reference, index, read,\n",
        "            k=k, w=w, max_mismatch=max_mismatch, seed_min=seed_min\n",
        "        )\n",
        "        # mismatch 허용 범위에서 복원\n",
        "        if pred_pos == true_pos and mm <= max_mismatch:\n",
        "            for j, base in enumerate(read):\n",
        "                reconstructed[pred_pos + j] = base\n",
        "            matched_reads += 1\n",
        "\n",
        "    return ''.join(reconstructed), matched_reads, total_reads\n",
        "\n",
        "# 정확도 계산\n",
        "def evaluate_reconstruction(reference, reconstructed):\n",
        "    assert len(reference) == len(reconstructed)\n",
        "    L = len(reference)\n",
        "    matches = sum(1 for a, b in zip(reference, reconstructed) if a == b)\n",
        "    return matches / L\n",
        "\n",
        "# 매핑 및 평가\n",
        "def run_mapping_and_evaluation():\n",
        "\n",
        "    K = 20\n",
        "    W = 8\n",
        "    MAX_OCC = 500\n",
        "    MAX_MM = 2\n",
        "    SEED_MIN = 2\n",
        "\n",
        "    pairs = [\n",
        "        (\"reference_1M.txt\",  \"mammoth_reads_100K.txt\",  \"ground_truth_100K.txt\"),\n",
        "        (\"reference_10M.txt\", \"mammoth_reads_1M.txt\",   \"ground_truth_1M.txt\"),\n",
        "        (\"reference_100M.txt\",\"mammoth_reads_10M.txt\",  \"ground_truth_10M.txt\"),\n",
        "        #(\"reference_1T.txt\",  \"mammoth_reads_100M.txt\", \"ground_truth_100M.txt\"),\n",
        "    ]\n",
        "\n",
        "    for ref_file, read_file, truth_file in pairs:\n",
        "        if not (os.path.exists(ref_file) and os.path.exists(read_file) and os.path.exists(truth_file)):\n",
        "            print(f\"> Skipping {ref_file} / {read_file} / {truth_file}: 파일이 존재하지 않음.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n=== Processing {ref_file} & {read_file} ===\")\n",
        "        reference = load_reference_to_string(ref_file)\n",
        "        reads = load_reads_from_file(read_file)\n",
        "        truth_positions = load_truth_positions(truth_file)\n",
        "\n",
        "        print(\"> Building minimizer index ...\")\n",
        "        index = build_minimizer_index(reference, k=K, w=W, max_occ=MAX_OCC)\n",
        "        print(f\"  - Unique minimizers after filtering: {len(index)}\")\n",
        "\n",
        "        print(\"> Performing mapping & reconstruction ...\")\n",
        "        reconstructed, matched_reads, total_reads = reconstruct_genome_with_reads(\n",
        "            reference, reads, truth_positions, index,\n",
        "            k=K, w=W, max_mismatch=MAX_MM, seed_min=SEED_MIN\n",
        "        )\n",
        "\n",
        "        read_level_acc = matched_reads / total_reads * 100\n",
        "        base_level_acc = evaluate_reconstruction(reference, reconstructed) * 100\n",
        "\n",
        "        print(f\"  * Read-level mapping accuracy (exact 위치 매칭 & ≤{MAX_MM} mismatch): \"\n",
        "              f\"{matched_reads}/{total_reads} = {read_level_acc:.2f}%\")\n",
        "        print(f\"  * Base-level reconstruction accuracy: {base_level_acc:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_mapping_and_evaluation()\n"
      ],
      "metadata": {
        "id": "3ByxEDGCVzPH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}