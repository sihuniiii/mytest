{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+tojOyo0nRwesIRqsqIEV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sihuniiii/mytest/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def generate_reference_to_file(filename, length, chunk_size=10_000_000):\n",
        "    bases = ['A', 'C', 'G', 'T']\n",
        "    with open(filename, 'w') as f:\n",
        "        written = 0\n",
        "        while written < length:\n",
        "            to_write = min(chunk_size, length - written)\n",
        "            seq_chunk = ''.join(random.choices(bases, k=to_write))\n",
        "            f.write(seq_chunk)\n",
        "            written += to_write\n",
        "\n",
        "def simulate_ancient_reads_to_file(\n",
        "    reference_file,\n",
        "    reads_filename,\n",
        "    truth_filename,\n",
        "    read_len,\n",
        "    num_reads,\n",
        "    mutation_rate=0.02\n",
        "):\n",
        "    with open(reference_file, 'r') as f:\n",
        "        reference_seq = f.read().strip()\n",
        "    L = len(reference_seq)\n",
        "\n",
        "    with open(reads_filename, 'w') as rf, open(truth_filename, 'w') as tf:\n",
        "        for i in range(num_reads):\n",
        "            start = random.randint(0, L - read_len)\n",
        "            original = list(reference_seq[start : start + read_len])\n",
        "            mutated = []\n",
        "            for j, base in enumerate(original):\n",
        "                prob = mutation_rate\n",
        "                if j < 5 or j >= read_len - 5:\n",
        "                    prob *= 5\n",
        "                if random.random() < prob:\n",
        "                    if base == 'C':\n",
        "                        mutated.append('T')\n",
        "                    elif base == 'G':\n",
        "                        mutated.append('A')\n",
        "                    else:\n",
        "                        mutated.append(random.choice(['A', 'C', 'G', 'T']))\n",
        "                else:\n",
        "                    mutated.append(base)\n",
        "            read_str = ''.join(mutated)\n",
        "            rf.write(read_str + '\\n')\n",
        "            tf.write(f\"{start}\\n\")\n",
        "\n",
        "def run_simulation():\n",
        "    settings = [\n",
        "        (1_000_000,100_000,\"1M\", \"100K\"),\n",
        "        (10_000_000,1_000_000,\"10M\", \"1M\"),\n",
        "        (100_000_000,10_000_000,\"100M\",\"10M\"),\n",
        "        (1_000_000_000,100_000_000,\"1T\", \"100M\"),\n",
        "    ]\n",
        "\n",
        "    # Reference 생성\n",
        "    for ref_len, _, ref_tag, _ in settings:\n",
        "        ref_filename = f\"reference_{ref_tag}.txt\"\n",
        "        if not os.path.exists(ref_filename):\n",
        "            generate_reference_to_file(ref_filename, ref_len)\n",
        "\n",
        "    for ref_len, num_reads, ref_tag, read_tag in settings:\n",
        "        ref_filename   = f\"reference_{ref_tag}.txt\"\n",
        "        reads_filename = f\"mammoth_reads_{read_tag}.txt\"\n",
        "        truth_filename = f\"ground_truth_{read_tag}.txt\"\n",
        "        read_len = 100\n",
        "\n",
        "        if not (os.path.exists(reads_filename) and os.path.exists(truth_filename)):\n",
        "            simulate_ancient_reads_to_file(\n",
        "                reference_file=ref_filename,\n",
        "                reads_filename=reads_filename,\n",
        "                truth_filename=truth_filename,\n",
        "                read_len=read_len,\n",
        "                num_reads=num_reads,\n",
        "                mutation_rate=0.01\n",
        "            )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_simulation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9nxK5bRo7oH",
        "outputId": "90dd1c3d-d119-4ce4-8edb-28aeb8539d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Reference file generated: reference_1M.txt (length=1000000)\n",
            "> Reference file generated: reference_10M.txt (length=10000000)\n",
            "> Reference file generated: reference_100M.txt (length=100000000)\n",
            "> Reference file generated: reference_1T.txt (length=1000000000)\n",
            "> Simulating reads for reference_1M.txt ...\n",
            "  - mammoth_reads_100K.txt: simulated 10000/100000 reads\n",
            "  - mammoth_reads_100K.txt: simulated 20000/100000 reads\n",
            "  - mammoth_reads_100K.txt: simulated 30000/100000 reads\n",
            "  - mammoth_reads_100K.txt: simulated 40000/100000 reads\n",
            "  - mammoth_reads_100K.txt: simulated 50000/100000 reads\n",
            "  - mammoth_reads_100K.txt: simulated 60000/100000 reads\n",
            "  - mammoth_reads_100K.txt: simulated 70000/100000 reads\n",
            "  - mammoth_reads_100K.txt: simulated 80000/100000 reads\n",
            "  - mammoth_reads_100K.txt: simulated 90000/100000 reads\n",
            "  - mammoth_reads_100K.txt: simulated 100000/100000 reads\n",
            "> Reads simulated: mammoth_reads_100K.txt (num_reads=100000, read_len=100)\n",
            "> Ground truth saved: ground_truth_100K.txt\n",
            "> Simulating reads for reference_10M.txt ...\n",
            "  - mammoth_reads_1M.txt: simulated 100000/1000000 reads\n",
            "  - mammoth_reads_1M.txt: simulated 200000/1000000 reads\n",
            "  - mammoth_reads_1M.txt: simulated 300000/1000000 reads\n",
            "  - mammoth_reads_1M.txt: simulated 400000/1000000 reads\n",
            "  - mammoth_reads_1M.txt: simulated 500000/1000000 reads\n",
            "  - mammoth_reads_1M.txt: simulated 600000/1000000 reads\n",
            "  - mammoth_reads_1M.txt: simulated 700000/1000000 reads\n",
            "  - mammoth_reads_1M.txt: simulated 800000/1000000 reads\n",
            "  - mammoth_reads_1M.txt: simulated 900000/1000000 reads\n",
            "  - mammoth_reads_1M.txt: simulated 1000000/1000000 reads\n",
            "> Reads simulated: mammoth_reads_1M.txt (num_reads=1000000, read_len=100)\n",
            "> Ground truth saved: ground_truth_1M.txt\n",
            "> Simulating reads for reference_100M.txt ...\n",
            "  - mammoth_reads_10M.txt: simulated 1000000/10000000 reads\n",
            "  - mammoth_reads_10M.txt: simulated 2000000/10000000 reads\n",
            "  - mammoth_reads_10M.txt: simulated 3000000/10000000 reads\n",
            "  - mammoth_reads_10M.txt: simulated 4000000/10000000 reads\n",
            "  - mammoth_reads_10M.txt: simulated 5000000/10000000 reads\n",
            "  - mammoth_reads_10M.txt: simulated 6000000/10000000 reads\n",
            "  - mammoth_reads_10M.txt: simulated 7000000/10000000 reads\n",
            "  - mammoth_reads_10M.txt: simulated 8000000/10000000 reads\n",
            "  - mammoth_reads_10M.txt: simulated 9000000/10000000 reads\n",
            "  - mammoth_reads_10M.txt: simulated 10000000/10000000 reads\n",
            "> Reads simulated: mammoth_reads_10M.txt (num_reads=10000000, read_len=100)\n",
            "> Ground truth saved: ground_truth_10M.txt\n",
            "> Simulating reads for reference_1T.txt ...\n",
            "  - mammoth_reads_100M.txt: simulated 10000000/100000000 reads\n",
            "  - mammoth_reads_100M.txt: simulated 20000000/100000000 reads\n",
            "  - mammoth_reads_100M.txt: simulated 30000000/100000000 reads\n",
            "  - mammoth_reads_100M.txt: simulated 40000000/100000000 reads\n",
            "  - mammoth_reads_100M.txt: simulated 50000000/100000000 reads\n",
            "  - mammoth_reads_100M.txt: simulated 60000000/100000000 reads\n",
            "  - mammoth_reads_100M.txt: simulated 70000000/100000000 reads\n",
            "  - mammoth_reads_100M.txt: simulated 80000000/100000000 reads\n",
            "  - mammoth_reads_100M.txt: simulated 90000000/100000000 reads\n",
            "  - mammoth_reads_100M.txt: simulated 100000000/100000000 reads\n",
            "> Reads simulated: mammoth_reads_100M.txt (num_reads=100000000, read_len=100)\n",
            "> Ground truth saved: ground_truth_100M.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#파일 불러오기\n",
        "def load_reference_to_string(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        return f.read().strip()\n",
        "\n",
        "def load_reads_from_file(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        return [line.strip() for line in f]\n",
        "\n",
        "def load_truth_positions(filename):\n",
        "    return [int(line.strip()) for line in open(filename, 'r')]\n",
        "\n",
        "\n",
        "# Minimizer 인덱스\n",
        "def build_minimizer_index(reference, k=20, w=8, max_occ=500):\n",
        "    index = {}\n",
        "    num_kmers = len(reference) - k + 1\n",
        "    for i in range(num_kmers - w + 1):\n",
        "        window_kmers = [reference[j:j + k] for j in range(i, i + w)]\n",
        "        mn = min(window_kmers)\n",
        "        mn_pos = i + window_kmers.index(mn)\n",
        "        index.setdefault(mn, []).append(mn_pos)\n",
        "\n",
        "    filtered = {m: poses for m, poses in index.items() if len(poses) <= max_occ}\n",
        "    return filtered\n",
        "\n",
        "# 매칭 알고리즘\n",
        "def minimizer_match(\n",
        "    reference,index,read,\n",
        "    k=20,w=8,\n",
        "    max_mismatch=2,seed_min=2\n",
        "):\n",
        "    read_kmers = [read[i:i + k] for i in range(len(read) - k + 1)]\n",
        "    read_min_pairs = []\n",
        "    for i in range(len(read_kmers) - w + 1):\n",
        "        window = read_kmers[i:i + w]\n",
        "        mn = min(window)\n",
        "        mn_idx = window.index(mn)\n",
        "        read_pos = i + mn_idx\n",
        "        read_min_pairs.append((mn, read_pos))\n",
        "\n",
        "    delta_counts = {}\n",
        "    for mn, rpos in read_min_pairs:\n",
        "        if mn not in index:\n",
        "            continue\n",
        "        for refpos in index[mn]:\n",
        "            delta = refpos - rpos\n",
        "            delta_counts[delta] = delta_counts.get(delta, 0) + 1\n",
        "\n",
        "    candidates = [d for d, cnt in delta_counts.items() if cnt >= seed_min]\n",
        "    best_pos, best_mm = -1, max_mismatch + 1\n",
        "\n",
        "    for delta in candidates:\n",
        "        if delta < 0 or delta + len(read) > len(reference):\n",
        "            continue\n",
        "        window_seq = reference[delta : delta + len(read)]\n",
        "        mismatches = sum(1 for a, b in zip(read, window_seq) if a != b)\n",
        "        if mismatches <= max_mismatch and mismatches < best_mm:\n",
        "            best_mm = mismatches\n",
        "            best_pos = delta\n",
        "\n",
        "    return best_pos, best_mm\n",
        "\n",
        "# 복원 함수\n",
        "def reconstruct_genome_with_reads(\n",
        "    reference,\n",
        "    reads,\n",
        "    truth_positions,\n",
        "    index,\n",
        "    k=20, w=8, max_mismatch=2, seed_min=2\n",
        "):\n",
        "    reconstructed = list(reference)\n",
        "    matched_reads = 0\n",
        "    total_reads = len(reads)\n",
        "\n",
        "    for i, read in enumerate(reads):\n",
        "        true_pos = truth_positions[i]\n",
        "        pred_pos, mm = minimizer_match(\n",
        "            reference, index, read,\n",
        "            k=k, w=w, max_mismatch=max_mismatch, seed_min=seed_min\n",
        "        )\n",
        "        # mismatch 허용 범위에서 복원\n",
        "        if pred_pos == true_pos and mm <= max_mismatch:\n",
        "            for j, base in enumerate(read):\n",
        "                reconstructed[pred_pos + j] = base\n",
        "            matched_reads += 1\n",
        "\n",
        "    return ''.join(reconstructed), matched_reads, total_reads\n",
        "\n",
        "# 정확도 계산\n",
        "def evaluate_reconstruction(reference, reconstructed):\n",
        "    assert len(reference) == len(reconstructed)\n",
        "    L = len(reference)\n",
        "    matches = sum(1 for a, b in zip(reference, reconstructed) if a == b)\n",
        "    return matches / L\n",
        "\n",
        "# 매핑 및 평가\n",
        "def run_mapping_and_evaluation():\n",
        "\n",
        "    K = 20\n",
        "    W = 8\n",
        "    MAX_OCC = 500\n",
        "    MAX_MM = 2\n",
        "    SEED_MIN = 2\n",
        "\n",
        "    pairs = [\n",
        "        (\"reference_1M.txt\",  \"mammoth_reads_100K.txt\",  \"ground_truth_100K.txt\"),\n",
        "        (\"reference_10M.txt\", \"mammoth_reads_1M.txt\",   \"ground_truth_1M.txt\"),\n",
        "        (\"reference_100M.txt\",\"mammoth_reads_10M.txt\",  \"ground_truth_10M.txt\"),\n",
        "        #(\"reference_1T.txt\",  \"mammoth_reads_100M.txt\", \"ground_truth_100M.txt\"),\n",
        "    ]\n",
        "\n",
        "    for ref_file, read_file, truth_file in pairs:\n",
        "        if not (os.path.exists(ref_file) and os.path.exists(read_file) and os.path.exists(truth_file)):\n",
        "            print(f\"> Skipping {ref_file} / {read_file} / {truth_file}: 파일이 존재하지 않음.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"\\n=== Processing {ref_file} & {read_file} ===\")\n",
        "        reference = load_reference_to_string(ref_file)\n",
        "        reads = load_reads_from_file(read_file)\n",
        "        truth_positions = load_truth_positions(truth_file)\n",
        "\n",
        "        print(\"> Building minimizer index ...\")\n",
        "        index = build_minimizer_index(reference, k=K, w=W, max_occ=MAX_OCC)\n",
        "        print(f\"  - Unique minimizers after filtering: {len(index)}\")\n",
        "\n",
        "        print(\"> Performing mapping & reconstruction ...\")\n",
        "        reconstructed, matched_reads, total_reads = reconstruct_genome_with_reads(\n",
        "            reference, reads, truth_positions, index,\n",
        "            k=K, w=W, max_mismatch=MAX_MM, seed_min=SEED_MIN\n",
        "        )\n",
        "\n",
        "        read_level_acc = matched_reads / total_reads * 100\n",
        "        base_level_acc = evaluate_reconstruction(reference, reconstructed) * 100\n",
        "\n",
        "        print(f\"  * Read-level mapping accuracy (exact 위치 매칭 & ≤{MAX_MM} mismatch): \"\n",
        "              f\"{matched_reads}/{total_reads} = {read_level_acc:.2f}%\")\n",
        "        print(f\"  * Base-level reconstruction accuracy: {base_level_acc:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_mapping_and_evaluation()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlfGZg-ApZFA",
        "outputId": "0073b42a-129d-4ebb-f3cc-6fbbbacb39ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Processing reference_1M.txt & mammoth_reads_100K.txt ===\n",
            "> Building minimizer index ...\n",
            "  - Unique minimizers after filtering: 241634\n",
            "> Performing mapping & reconstruction ...\n",
            "  * Read-level mapping accuracy (exact 위치 매칭 & ≤2 mismatch): 87743/100000 = 87.74%\n",
            "  * Base-level reconstruction accuracy: 99.08%\n",
            "\n",
            "=== Processing reference_10M.txt & mammoth_reads_1M.txt ===\n",
            "> Building minimizer index ...\n",
            "  - Unique minimizers after filtering: 2416185\n",
            "> Performing mapping & reconstruction ...\n",
            "  * Read-level mapping accuracy (exact 위치 매칭 & ≤2 mismatch): 875852/1000000 = 87.59%\n",
            "  * Base-level reconstruction accuracy: 99.07%\n",
            "\n",
            "=== Processing reference_100M.txt & mammoth_reads_10M.txt ===\n",
            "> Building minimizer index ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "gEgR1n65FbJh",
        "outputId": "601799e6-efd7-4bcf-c563-df248b7c2dfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAJDcz7_czs-",
        "outputId": "8a413faf-715e-428b-a77a-9764e9046ca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> Generated & saved reference length=10000\n",
            "> Simulated & saved 10000 ancient reads + ground truth\n",
            "> Built minimizer index (k=20, w=8, max_occ=500) with 2429 keys\n",
            "\n",
            ">> Reconstruction accuracy (≤2 mismatches): 87.84%\n",
            "> Mapping results saved to mapping_results.txt\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import sys\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Reference 생성 및 저장\n",
        "# ----------------------------\n",
        "def generate_artificial_elephant_genome(length=10000):\n",
        "    \"\"\"\n",
        "    코끼리 유전체처럼 보이는 염기서열을 인위적으로 생성.\n",
        "    length: 생성 길이 (기본 10,000bp; 실제 테스트 시 더 늘려도 됨)\n",
        "    \"\"\"\n",
        "    bases = ['A', 'C', 'G', 'T']\n",
        "    genome = ''.join(random.choices(bases, k=length))\n",
        "    return genome\n",
        "\n",
        "def save_reference_as_txt(sequence, filename=\"reference_10K.txt\"):\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(sequence)\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Short Read 시뮬레이션\n",
        "# ----------------------------\n",
        "def load_reference(filename=\"reference_10K.txt\"):\n",
        "    \"\"\"\n",
        "    저장된 reference 파일을 한 줄 문자열로 읽어서 반환.\n",
        "    \"\"\"\n",
        "    with open(filename, \"r\") as f:\n",
        "        return f.read().strip()\n",
        "\n",
        "def simulate_ancient_reads(\n",
        "    reference_seq,\n",
        "    read_len=100,\n",
        "    num_reads=10000,\n",
        "    mutation_rate=0.01\n",
        "):\n",
        "    \"\"\"\n",
        "    reference_seq에서 num_reads개 만큼 랜덤하게 잘라내고,\n",
        "    “고대 DNA 특성”에 따라 말단(C→T, G→A) 변이 삽입.\n",
        "    반환: (reads_list, truth_list)\n",
        "      - reads_list: 생성된 read 문자열 리스트\n",
        "      - truth_list: (read_id, start_position, mutation_count) 튜플 리스트\n",
        "    \"\"\"\n",
        "    reads = []\n",
        "    truth = []\n",
        "    L = len(reference_seq)\n",
        "    for i in range(num_reads):\n",
        "        # 0 ~ L-read_len 사이에서 랜덤 시작점 선택\n",
        "        start = random.randint(0, L - read_len)\n",
        "        original = list(reference_seq[start:start + read_len])\n",
        "        mutated = []\n",
        "        mutation_count = 0\n",
        "\n",
        "        for j in range(read_len):\n",
        "            # 말단(j<5 또는 j>=read_len-5)에선 변이 확률을 5배 증가\n",
        "            prob = mutation_rate\n",
        "            if j < 5 or j >= read_len - 5:\n",
        "                prob *= 5\n",
        "\n",
        "            base = original[j]\n",
        "            if random.random() < prob:\n",
        "                # C→T, G→A 우선 치환. 나머지는 랜덤 선택\n",
        "                if base == 'C':\n",
        "                    mutated.append('T')\n",
        "                elif base == 'G':\n",
        "                    mutated.append('A')\n",
        "                else:\n",
        "                    mutated.append(random.choice(['A', 'C', 'G', 'T']))\n",
        "                mutation_count += 1\n",
        "            else:\n",
        "                mutated.append(base)\n",
        "\n",
        "        read_str = ''.join(mutated)\n",
        "        reads.append(read_str)\n",
        "        truth.append((f'read_{i}', start, mutation_count))\n",
        "\n",
        "    return reads, truth\n",
        "\n",
        "def save_reads_and_truth(\n",
        "    reads,\n",
        "    truth,\n",
        "    reads_filename=\"mammoth_reads_10K.txt\",\n",
        "    truth_filename=\"ground_truth_10K.txt\"\n",
        "):\n",
        "    # reads만 한 줄씩 저장\n",
        "    with open(reads_filename, \"w\") as f:\n",
        "        for read in reads:\n",
        "            f.write(read + \"\\n\")\n",
        "    # ground truth 위치(start position)만 저장\n",
        "    with open(truth_filename, \"w\") as f:\n",
        "        for _, pos, _ in truth:\n",
        "            f.write(f\"{pos}\\n\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3) 개선된 Minimizer 인덱스 구축 + Seed Chaining 매칭\n",
        "# ---------------------------------------------------------\n",
        "def build_minimizer_index(reference, k=20, w=8, max_occ=500):\n",
        "    \"\"\"\n",
        "    reference: ACGT 문자열\n",
        "    k: k-mer 길이\n",
        "    w: 윈도우 크기 (k-mer 개수)\n",
        "    max_occ: 인덱스에서 허용할 minimizer 최대 출현 횟수\n",
        "             (너무 자주 나오는 minimizer는 필터링)\n",
        "    반환: { minimizer_kmer: [pos1, pos2, ...], ... }\n",
        "    \"\"\"\n",
        "    index = {}\n",
        "    num_kmers = len(reference) - k + 1\n",
        "    # i: 윈도우의 시작 오프셋(0 ≤ i ≤ num_kmers - w)\n",
        "    for i in range(num_kmers - w + 1):\n",
        "        window_kmers = [reference[j:j+k] for j in range(i, i + w)]\n",
        "        mn = min(window_kmers)\n",
        "        mn_pos = i + window_kmers.index(mn)  # minimizer의 실제 reference 상 위치\n",
        "        index.setdefault(mn, []).append(mn_pos)\n",
        "\n",
        "    # 고빈도 minimizer 제거: 등장 빈도가 max_occ 초과면 제외\n",
        "    filtered = {m: poses for m, poses in index.items() if len(poses) <= max_occ}\n",
        "    return filtered\n",
        "\n",
        "def minimizer_match(\n",
        "    reference,\n",
        "    index,\n",
        "    read,\n",
        "    k=20,\n",
        "    w=8,\n",
        "    max_mismatch=2,\n",
        "    seed_min=2\n",
        "):\n",
        "    \"\"\"\n",
        "    reference: 전체 ACGT 문자열\n",
        "    index: build_minimizer_index 결과물\n",
        "    read: 하나의 read 문자열\n",
        "    k, w: build 때 사용한 k-mer, 윈도우 크기\n",
        "    max_mismatch: 허용 mismatch 개수\n",
        "    seed_min: seed chaining 시, 동일 delta(오프셋) 후보에 필요한 최소 시드 개수\n",
        "\n",
        "    동작:\n",
        "      1) read에서 sliding 최소 minimizer(k-mer)를 구하고, (minimizer, read 내 위치) 쌍 생성\n",
        "      2) 각 minimizer가 reference 인덱스에서 등장하는 모든 pos마다 (refpos - readpos = delta) 계산하여 빈도 집계\n",
        "      3) delta 빈도가 seed_min 이상인 δ(후보 alignment 오프셋)만 후보로 선정\n",
        "      4) 후보 δ마다 read 전체와 reference[δ:δ+len(read)] 간 mismatch를 계산 → best 위치 반환\n",
        "\n",
        "    반환: (best_pos, best_mismatch)\n",
        "      - best_pos = 예측된 reference 상 alignment 시작 오프셋,\n",
        "        예측 실패 시 -1 반환.\n",
        "      - best_mismatch = 해당 위치에서 계산된 mismatch 개수\n",
        "    \"\"\"\n",
        "    read_kmers = [read[i:i+k] for i in range(len(read) - k + 1)]\n",
        "    # read 내 윈도우마다 minimizer와 read내 위치를 찾음\n",
        "    read_min_pairs = []\n",
        "    for i in range(len(read_kmers) - w + 1):\n",
        "        window = read_kmers[i:i + w]\n",
        "        mn = min(window)\n",
        "        # minimizer 위치: read에서 i부터 i+w-1 사이에 처음 등장한 위치\n",
        "        mn_idx_in_window = window.index(mn)\n",
        "        read_pos = i + mn_idx_in_window\n",
        "        read_min_pairs.append((mn, read_pos))\n",
        "\n",
        "    # (refpos - readpos = delta) 빈도 세기\n",
        "    delta_counts = {}\n",
        "    for (mn, rpos) in read_min_pairs:\n",
        "        if mn not in index:\n",
        "            continue\n",
        "        for refpos in index[mn]:\n",
        "            delta = refpos - rpos\n",
        "            delta_counts[delta] = delta_counts.get(delta, 0) + 1\n",
        "\n",
        "    # seed_min 개수 이상 지원하는 δ만 후보로\n",
        "    candidates = [d for d, cnt in delta_counts.items() if cnt >= seed_min]\n",
        "    best_pos, best_mm = -1, max_mismatch + 1\n",
        "\n",
        "    for delta in candidates:\n",
        "        if delta < 0 or delta + len(read) > len(reference):\n",
        "            continue\n",
        "        window_seq = reference[delta : delta + len(read)]\n",
        "        # simple Hamming distance(불일치 개수) 계산\n",
        "        mismatches = sum(1 for a, b in zip(read, window_seq) if a != b)\n",
        "        if mismatches <= max_mismatch and mismatches < best_mm:\n",
        "            best_mm = mismatches\n",
        "            best_pos = delta\n",
        "\n",
        "    return best_pos, best_mm\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4) 전체 파이프라인 실행\n",
        "# ---------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # ───────────\n",
        "    # 1) Reference 생성 & 저장\n",
        "    # ───────────\n",
        "    # (테스트를 위해 length=10000; 실제 1M 이상으로 늘려서 쓰세요)\n",
        "    REF_LEN = 10000\n",
        "    reference_seq = generate_artificial_elephant_genome(length=REF_LEN)\n",
        "    save_reference_as_txt(reference_seq, filename=\"reference_10K.txt\")\n",
        "    print(f\"> Generated & saved reference length={REF_LEN}\")\n",
        "\n",
        "    # ───────────\n",
        "    # 2) Short Read 시뮬레이션 & 저장\n",
        "    # ───────────\n",
        "    read_length = 100       # read 길이(예: 100bp)\n",
        "    num_reads = 10000       # read 개수\n",
        "    mutation_rate = 0.01    # 기본 변이율\n",
        "    reads, truth = simulate_ancient_reads(\n",
        "        reference_seq,\n",
        "        read_len=read_length,\n",
        "        num_reads=num_reads,\n",
        "        mutation_rate=mutation_rate\n",
        "    )\n",
        "    save_reads_and_truth(\n",
        "        reads,\n",
        "        truth,\n",
        "        reads_filename=\"mammoth_reads_10K.txt\",\n",
        "        truth_filename=\"ground_truth_10K.txt\"\n",
        "    )\n",
        "    print(f\"> Simulated & saved {num_reads} ancient reads + ground truth\")\n",
        "\n",
        "    # ───────────\n",
        "    # 3) 인덱스 구축\n",
        "    # ───────────\n",
        "    # tuning parameter\n",
        "    K = 20           # k-mer 길이\n",
        "    W = 8            # 윈도우 크기\n",
        "    MAX_OCC = 500    # 고빈도 minimizer 허용 최대 등장횟수\n",
        "    index = build_minimizer_index(\n",
        "        reference_seq,\n",
        "        k=K,\n",
        "        w=W,\n",
        "        max_occ=MAX_OCC\n",
        "    )\n",
        "    print(f\"> Built minimizer index (k={K}, w={W}, max_occ={MAX_OCC}) with {len(index)} keys\")\n",
        "\n",
        "    # ───────────\n",
        "    # 4) 매핑 & 정확도 평가\n",
        "    # ───────────\n",
        "    MAX_MM = 2       # 허용 mismatch 개수\n",
        "    SEED_MIN = 2     # seed chaining 최소 시드 개수\n",
        "\n",
        "    correct = 0\n",
        "    for i, read in enumerate(reads):\n",
        "        true_pos = truth[i][1]  # ground truth start position\n",
        "        pred_pos, mm = minimizer_match(\n",
        "            reference_seq,\n",
        "            index,\n",
        "            read,\n",
        "            k=K,\n",
        "            w=W,\n",
        "            max_mismatch=MAX_MM,\n",
        "            seed_min=SEED_MIN\n",
        "        )\n",
        "        if pred_pos == true_pos:\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / num_reads * 100\n",
        "    print(f\"\\n>> Reconstruction accuracy (≤{MAX_MM} mismatches): {accuracy:.2f}%\")\n",
        "\n",
        "    # ───────────\n",
        "    # (추가) 매핑 결과를 파일에 기록하고 싶다면 주석 해제\n",
        "    # ───────────\n",
        "    with open(\"mapping_results.txt\", \"w\") as outf:\n",
        "         outf.write(\"read_id\\ttrue_pos\\tpred_pos\\tmismatch\\n\")\n",
        "         for idx, read in enumerate(reads):\n",
        "             tp = truth[idx][1]\n",
        "             pp, mm = minimizer_match(\n",
        "                 reference_seq, index, read,\n",
        "                 k=K, w=W, max_mismatch=MAX_MM, seed_min=SEED_MIN\n",
        "             )\n",
        "             outf.write(f\"read_{idx}\\t{tp}\\t{pp}\\t{mm}\\n\")\n",
        "    print(\"> Mapping results saved to mapping_results.txt\")\n"
      ]
    }
  ]
}